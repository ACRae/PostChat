%\vspace{1cm}
%\begin{flushleft} 
%\fontsize{16}{24}\textbf{Lista de Acr√≥nimos} 
%\end{flushleft} 
%\vspace{1cm}
\prefacesection{List of Symbols and Notation}
\vspace{-2cm}
The most frequent symbols and notation are as follows.
\hrule
\begin{table}[h]
\begin{tabular}{@{}l@{\hspace{.5cm}}l} \\
$c,$	 		& number of different classes in a dataset \vspace{-2mm} \\
$d,$	 		& dimensionality or number of features in a dataset \vspace{-2mm} \\
$L,$ 			& cumulative threshold for feature selection \vspace{-2mm} \\
$m,$	 		& number of selected features \vspace{-2mm} \\
$M_S,$    & maximum allowed similarity \vspace{-2mm} \\  
$n,$	    & number of instances in a dataset \vspace{-2mm} \\
$q,$      & maximum number of bits to discretize a given feature \vspace{-2mm} \\
$s,$      & number of sampled instances from a dataset \vspace{-2mm} \\ 
${\bf x}_i,$  & the $i$-th feature vector $\in \mathbf{R}^d$ \vspace{-2mm} \\ 
$X_i,$ & feature $i$ with $i \in \{1,\ldots,d\}$ \vspace{1cm} \\ 

$\eta,$   & percentage of features to keep in the DDF and the DDW methods \vspace{-2mm} \\
$\ell_0,$ & $\ell_0$ norm for a vector \vspace{-2mm} \\
$\Delta,$  & maximum allowed distortion \vspace{1cm} \\

$\mathcal{D},$ & dataset \vspace{-2mm} \\
$\mathcal{X, Y},$   & random variable \vspace{1cm} \\

$H(.),$ & entropy of a random variable \vspace{-2mm} \\
$H(.|.),$ & conditional entropy of one random variable given another \vspace{-2mm} \\
$I(.),$  & self-information of a specific random variable outcome \vspace{-2mm} \\
$I(.;.),$  & mutual-information between a pair of random variables \vspace{-2mm} \\

\end{tabular}
\end{table}



